# Atelier 3 - Partie 5 : Int√©gration de Base de Donn√©es PostgreSQL

**Dur√©e** : 60-90 minutes
**Pr√©requis** : Atelier 3 (Parties 1-4) compl√©t√©
**Niveau** : Interm√©diaire

‚ö†Ô∏è **IMPORTANT** : Cette partie est **optionnelle** et s'ajoute apr√®s l'Atelier 3. Les Ateliers 1 et 2 utilisent le stockage en m√©moire. Vous allez maintenant migrer vers une vraie base de donn√©es !

## üìö Documents Disponibles

Ce guide est le **document principal** pour l'int√©gration de la base de donn√©es. Deux ressources sont disponibles :

1. **[workshop-3-database.md](workshop-3-database.md)** (ce document) - **Tutorial complet** avec explications d√©taill√©es
2. **[MIGRATION_CHECKLIST.md](MIGRATION_CHECKLIST.md)** - **Checklist visuelle rapide** pour r√©f√©rence

üí° **Astuce** : Lisez d'abord ce document en entier, puis utilisez la checklist pendant l'impl√©mentation.

## üéØ Objectifs

√Ä la fin de cette section, vous serez capable de :

- Comprendre pourquoi utiliser une base de donn√©es persistante vs stockage en m√©moire
- Configurer **PostgreSQL avec Render** pour la production
- Impl√©menter **SQLAlchemy ORM** pour l'acc√®s aux donn√©es
- Migrer du stockage en m√©moire vers une base de donn√©es relationnelle
- Adapter les tests pour fonctionner avec la base de donn√©es
- D√©ployer l'application avec PostgreSQL en production

## üìã Pourquoi PostgreSQL ?

### Limitations du Stockage en M√©moire

L'impl√©mentation actuelle utilise une simple liste Python :

```python
tasks_storage: List[Task] = []
```

**Probl√®mes** :
- ‚ùå Les donn√©es sont perdues √† chaque red√©marrage du serveur
- ‚ùå Ne supporte pas le scaling horizontal (plusieurs instances)
- ‚ùå Pas de requ√™tes complexes ni de relations
- ‚ùå Pas de transactions ni d'int√©grit√© des donn√©es

### Avantages de PostgreSQL

- ‚úÖ **Persistance** : Les donn√©es survivent aux red√©marrages
- ‚úÖ **Scalabilit√©** : Supporte plusieurs instances de l'application
- ‚úÖ **ACID** : Transactions atomiques, coh√©rence des donn√©es
- ‚úÖ **Requ√™tes complexes** : Filtrage, jointures, agr√©gations
- ‚úÖ **Int√©grit√©** : Contraintes, cl√©s √©trang√®res, validations
- ‚úÖ **Standard industriel** : Utilis√© en production partout

## ‚öôÔ∏è Vue d'Ensemble de la Migration

Cette partie va transformer votre application pour utiliser PostgreSQL au lieu du stockage en m√©moire.

### Ce que vous allez faire

**√âtape 1** : Ajouter les d√©pendances PostgreSQL
**√âtape 2** : Cr√©er les nouveaux fichiers (database.py, models.py)
**√âtape 3** : Modifier app.py pour utiliser la base de donn√©es
**√âtape 4** : Adapter les tests
**√âtape 5** : D√©ployer sur Render avec PostgreSQL

**Temps estim√©** : 60-90 minutes

## üèóÔ∏è Architecture de la Solution

### Fichiers √† CR√âER (nouveaux)

```text
backend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ database.py         # ‚ú® NOUVEAU - Configuration SQLAlchemy
‚îÇ   ‚îú‚îÄ‚îÄ models.py           # ‚ú® NOUVEAU - Mod√®les ORM
‚îÇ   ‚îî‚îÄ‚îÄ db_init.py          # ‚ú® NOUVEAU - Scripts d'initialisation
‚îú‚îÄ‚îÄ .env.example            # ‚ú® NOUVEAU - Template variables d'environnement
‚îî‚îÄ‚îÄ .gitignore              # ‚ú® NOUVEAU - Fichiers √† ignorer
```

### Fichiers √† MODIFIER (existants)

```text
backend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ app.py              # üîß MODIFIER - Remplacer tasks_storage par DB
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py         # üîß MODIFIER - Ajouter fixtures de test DB
‚îî‚îÄ‚îÄ pyproject.toml          # üîß MODIFIER - Ajouter SQLAlchemy, psycopg2
```

### Stack Technique

- **SQLAlchemy 2.0** : ORM Python moderne
- **psycopg2** : Driver PostgreSQL pour Python
- **PostgreSQL 15** : Base de donn√©es relationnelle
- **Render Postgres** : Service manag√© cloud

## üìù √âtape 0 : Point de D√©part

Avant de commencer, assurez-vous que :

- ‚úÖ Vous avez compl√©t√© les Ateliers 1, 2 et 3 (parties 1-4)
- ‚úÖ Votre application utilise actuellement `tasks_storage: List[Task] = []`
- ‚úÖ Tous vos tests passent
- ‚úÖ Votre application est d√©ploy√©e sur Render

**Si vous n'avez pas fait les ateliers pr√©c√©dents**, cette partie ne fonctionnera pas seule !

### üìã Aide-M√©moire Rapide

Si vous voulez une **checklist visuelle** de ce qu'il faut supprimer/garder/modifier, consultez:

üëâ **[MIGRATION_CHECKLIST.md](MIGRATION_CHECKLIST.md)** - Vue d'ensemble avec diagrammes

Ce guide ci-dessous vous montre **tous les d√©tails** √©tape par √©tape. La checklist est un r√©sum√© visuel pour vous aider √† vous rep√©rer.

## üìö Partie 1 : Comprendre les Fichiers Ajout√©s

### 1.1 Configuration de la Base de Donn√©es (`database.py`)

Ce module g√®re la connexion √† la base de donn√©es :

```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy.ext.declarative import declarative_base

# R√©cup√©rer l'URL de la base de donn√©es
DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///./taskflow.db")

# Cr√©er le moteur SQLAlchemy
engine = create_engine(DATABASE_URL)

# Cr√©er une factory de sessions
SessionLocal = sessionmaker(bind=engine)

# Base pour les mod√®les ORM
Base = declarative_base()
```

**Points cl√©s** :
- `DATABASE_URL` : Render fournit automatiquement cette variable
- `engine` : G√®re le pool de connexions
- `SessionLocal` : Cr√©e des sessions pour les transactions
- `Base` : Classe parente pour tous les mod√®les

### 1.2 Mod√®les de Donn√©es (`models.py`)

D√©finit le sch√©ma de la base de donn√©es :

```python
from sqlalchemy import Column, String, DateTime, Enum
from .database import Base

class TaskModel(Base):
    __tablename__ = "tasks"

    id = Column(String, primary_key=True)
    title = Column(String(200), nullable=False)
    description = Column(String(1000))
    status = Column(Enum(TaskStatus))
    priority = Column(Enum(TaskPriority))
    assignee = Column(String(100))
    due_date = Column(DateTime)
    created_at = Column(DateTime, server_default=func.now())
    updated_at = Column(DateTime, onupdate=func.now())
```

**Points cl√©s** :
- `__tablename__` : Nom de la table SQL
- `Column` : D√©finit les colonnes avec types et contraintes
- `server_default` : Valeur par d√©faut g√©r√©e par la DB
- `onupdate` : Mise √† jour automatique du timestamp

### 1.3 Dependency Injection

FastAPI utilise `Depends()` pour injecter la session DB :

```python
from fastapi import Depends
from sqlalchemy.orm import Session
from .database import get_db

@app.get("/tasks")
async def list_tasks(db: Session = Depends(get_db)):
    tasks = db.query(TaskModel).all()
    return tasks
```

**Avantages** :

- Session cr√©√©e automatiquement pour chaque requ√™te
- Ferm√©e automatiquement apr√®s la requ√™te
- Facile √† mocker pour les tests

## üî® Partie 2 : Impl√©mentation √âtape par √âtape

**üéØ Objectif** : Migrer du stockage en m√©moire vers PostgreSQL en modifiant votre code existant.

### √âtape 2.1 : Ajouter les D√©pendances

**Fichier √† modifier** : `backend/pyproject.toml`

Trouvez la section `dependencies` et ajoutez SQLAlchemy et psycopg2 :

```toml
dependencies = [
    "fastapi>=0.104.1",
    "uvicorn[standard]>=0.24.0",
    "pydantic>=2.5.0",
    "httpx>=0.25.2",
    "sqlalchemy>=2.0.23",      # ‚ú® AJOUTER CETTE LIGNE
    "psycopg2-binary>=2.9.9",  # ‚ú® AJOUTER CETTE LIGNE
]
```

**Installer les d√©pendances** :

```bash
cd backend
uv sync
```

**Ajuster la couverture de tests** (optionnel) :

Dans `pyproject.toml`, trouvez `--cov-fail-under=90` et changez-le √† `70` (car on ajoute de nouveaux fichiers) :

```toml
addopts = [
    "--cov=src",
    "--cov-report=term-missing",
    "--cov-report=html",
    "--cov-fail-under=70",  # üîß MODIFIER de 90 √† 70
]
```

### √âtape 2.2 : Cr√©er le Module de Configuration Database

**Fichier √† cr√©er** : `backend/src/database.py`

Cr√©ez ce nouveau fichier avec le contenu suivant :

```python
"""
Database configuration and session management.
"""

import os
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session, declarative_base
from typing import Generator
import logging

logger = logging.getLogger("taskflow")

# Database URL - Render provides DATABASE_URL automatically
DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "sqlite:///./taskflow.db"  # Local SQLite fallback
)

# Fix for Render's postgres:// URL
if DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)

logger.info(f"Connecting to database: {DATABASE_URL.split('@')[0]}...")

# Create engine
engine_kwargs = {}
if DATABASE_URL.startswith("sqlite"):
    engine_kwargs["connect_args"] = {"check_same_thread": False}
else:
    engine_kwargs.update({
        "pool_size": 5,
        "max_overflow": 10,
        "pool_pre_ping": True,
    })

engine = create_engine(DATABASE_URL, **engine_kwargs)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()


def get_db() -> Generator[Session, None, None]:
    """Dependency function to get database session."""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


def init_db() -> None:
    """Initialize the database by creating all tables."""
    logger.info("Initializing database tables...")
    Base.metadata.create_all(bind=engine)
    logger.info("Database tables created successfully!")


def drop_db() -> None:
    """Drop all database tables. WARNING: This will delete all data!"""
    logger.warning("Dropping all database tables...")
    Base.metadata.drop_all(bind=engine)
    logger.warning("All tables dropped!")
```

### √âtape 2.3 : Cr√©er les Mod√®les ORM

**Fichier √† cr√©er** : `backend/src/models.py`

```python
"""
Database models for TaskFlow application.
"""

from sqlalchemy import Column, String, DateTime, Enum as SQLEnum
from sqlalchemy.sql import func
from .database import Base
from enum import Enum


class TaskStatus(str, Enum):
    TODO = "todo"
    IN_PROGRESS = "in_progress"
    DONE = "done"


class TaskPriority(str, Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"


class TaskModel(Base):
    """SQLAlchemy model for tasks table."""
    __tablename__ = "tasks"

    id = Column(String, primary_key=True, index=True)
    title = Column(String(200), nullable=False)
    description = Column(String(1000), nullable=True)
    status = Column(
        SQLEnum(TaskStatus, values_callable=lambda x: [e.value for e in x]),
        nullable=False,
        default=TaskStatus.TODO.value
    )
    priority = Column(
        SQLEnum(TaskPriority, values_callable=lambda x: [e.value for e in x]),
        nullable=False,
        default=TaskPriority.MEDIUM.value
    )
    assignee = Column(String(100), nullable=True)
    due_date = Column(DateTime, nullable=True)
    created_at = Column(DateTime, nullable=False, server_default=func.now())
    updated_at = Column(DateTime, nullable=False, server_default=func.now(), onupdate=func.now())

    def __repr__(self):
        return f"<Task(id={self.id}, title={self.title}, status={self.status})>"
```

### √âtape 2.4 : Modifier app.py pour Utiliser la Base de Donn√©es

**Fichier √† modifier** : `backend/src/app.py`

**Changement 1** : Modifier les imports (d√©but du fichier)

```python
# AVANT (Atelier 1-3)
from typing import List, Optional
from uuid import uuid4
from datetime import datetime
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field, ConfigDict
from enum import Enum

# APR√àS (avec Database)
from typing import List, Optional
from uuid import uuid4
from datetime import datetime
from fastapi import FastAPI, HTTPException, Depends  # ‚ú® Ajouter Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse  # ‚ú® Ajouter JSONResponse
from pydantic import BaseModel, Field, ConfigDict
from sqlalchemy.orm import Session  # ‚ú® NOUVEAU
from sqlalchemy import text  # ‚ú® NOUVEAU

# Import database and models  # ‚ú® NOUVEAU
from .database import get_db, init_db  # ‚ú® NOUVEAU
from .models import TaskModel, TaskStatus, TaskPriority  # ‚ú® NOUVEAU
```

**Changement 2** : Supprimer les enums Pydantic et le stockage en m√©moire

**‚ö†Ô∏è IMPORTANT** : Trouvez et supprimez ces sections dans votre `app.py` :

**a) Supprimer les d√©finitions d'Enum** (autour de la ligne 27-37) :

```python
# ‚ùå TROUVEZ ET SUPPRIMEZ COMPL√àTEMENT CES LIGNES
class TaskStatus(str, Enum):
    TODO = "todo"
    IN_PROGRESS = "in_progress"
    DONE = "done"


class TaskPriority(str, Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
```

**Raison** : Ces enums sont maintenant dans `models.py` et seront import√©s depuis l√†.

**b) Supprimer le stockage en m√©moire** (autour de la ligne 71) :

```python
# ‚ùå TROUVEZ ET SUPPRIMEZ CETTE LIGNE
tasks_storage: List[Task] = []
```

**Raison** : On n'utilise plus de liste en m√©moire, on utilise la base de donn√©es.

**c) Supprimer la fixture reset_storage des imports** (si pr√©sente dans conftest.py) :

```python
# ‚ùå DANS conftest.py, SUPPRIMEZ CES LIGNES SI PR√âSENTES
from src.app import app, tasks_storage  # ‚ùå ENLEVER tasks_storage

@pytest.fixture(autouse=True)
def reset_storage():
    """Clean the task storage..."""
    tasks_storage.clear()  # ‚ùå TOUT CE BLOC √Ä SUPPRIMER
    yield
    tasks_storage.clear()
```

**Apr√®s suppression**, votre `app.py` devrait ressembler √† :

```python
# D√©but du fichier
from contextlib import asynccontextmanager
from typing import List, Optional
from uuid import uuid4
from datetime import datetime
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, ConfigDict
from sqlalchemy.orm import Session
from sqlalchemy import text
import logging
import os

# Import database and models
from .database import get_db, init_db
from .models import TaskModel, TaskStatus, TaskPriority

# Configure logging
logging.basicConfig(...)

# Pydantic Models (for API validation) - GARDER CECI
class TaskBase(BaseModel):
    model_config = ConfigDict(use_enum_values=True)
    title: str = Field(..., min_length=1, max_length=200)
    # ... reste des champs
```

**Note** : Les mod√®les Pydantic (`TaskBase`, `TaskCreate`, `TaskUpdate`, `Task`) doivent √™tre **conserv√©s** - on les utilise toujours pour la validation de l'API !

**Changement 3** : Modifier la fonction lifespan

```python
# AVANT
@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("üöÄ TaskFlow backend starting up...")
    yield
    logger.info("üõë TaskFlow backend shutting down...")

# APR√àS
@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("üöÄ TaskFlow backend starting up...")

    # ‚ú® AJOUTER ces lignes
    if not app.dependency_overrides:
        logger.info("Initializing database...")
        init_db()
        logger.info("‚úÖ Database ready!")
    else:
        logger.info("Test mode - skipping database initialization")

    yield
    logger.info("üõë TaskFlow backend shutting down...")
```

**Changement 4** : Modifier le health check

```python
# AVANT
@app.get("/health")
async def health_check():
    environment = os.getenv("ENVIRONMENT", "development")
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "environment": environment,
        "version": "2.1.0",
        "storage": "in-memory"
    }

# APR√àS
@app.get("/health")
async def health_check(db: Session = Depends(get_db)):  # ‚ú® Ajouter db parameter
    environment = os.getenv("ENVIRONMENT", "development")

    # ‚ú® AJOUTER: Check database connection
    try:
        db.execute(text("SELECT 1"))
        db_status = "connected"
    except Exception as e:
        logger.error(f"Database health check failed: {e}")
        db_status = "error"

    return {
        "status": "healthy" if db_status == "connected" else "degraded",
        "timestamp": datetime.utcnow().isoformat(),
        "environment": environment,
        "version": "2.2.0",  # ‚ú® Mettre √† jour la version
        "storage": "postgresql" if "postgresql" in os.getenv("DATABASE_URL", "") else "sqlite",
        "database": db_status  # ‚ú® AJOUTER
    }
```

**Changement 5** : Modifier les endpoints CRUD

Je vais vous montrer les changements pour chaque endpoint. **Remplacez** vos endpoints existants par ces versions :

**a) List Tasks**

```python
# APR√àS
@app.get("/tasks", response_model=List[Task])
async def list_tasks(
    status: Optional[TaskStatus] = None,
    priority: Optional[TaskPriority] = None,
    assignee: Optional[str] = None,
    db: Session = Depends(get_db)  # ‚ú® AJOUTER ce param√®tre
):
    """List all tasks with optional filtering."""
    query = db.query(TaskModel)  # ‚ú® Utiliser DB au lieu de tasks_storage

    if status:
        query = query.filter(TaskModel.status == status.value)
    if priority:
        query = query.filter(TaskModel.priority == priority.value)
    if assignee:
        query = query.filter(TaskModel.assignee == assignee)

    tasks = query.all()
    return tasks
```

**b) Create Task**

```python
# APR√àS
@app.post("/tasks", response_model=Task, status_code=201)
async def create_task(task_data: TaskCreate, db: Session = Depends(get_db)):  # ‚ú® AJOUTER db
    """Create a new task."""
    logger.info(f"Creating task: {task_data.title}")

    # ‚ú® Cr√©er un mod√®le DB au lieu d'un objet Pydantic
    db_task = TaskModel(
        id=str(uuid4()),
        **task_data.model_dump()
    )

    # ‚ú® Sauvegarder en base de donn√©es
    db.add(db_task)
    db.commit()
    db.refresh(db_task)

    logger.info(f"Task created successfully: {db_task.id}")
    return db_task
```

**c) Get Task**

```python
# APR√àS
@app.get("/tasks/{task_id}", response_model=Task)
async def get_task(task_id: str, db: Session = Depends(get_db)):  # ‚ú® AJOUTER db
    """Get a specific task by ID."""
    task = db.query(TaskModel).filter(TaskModel.id == task_id).first()

    if not task:
        raise HTTPException(status_code=404, detail=f"Task with ID '{task_id}' not found")

    return task
```

**d) Update Task**

```python
# APR√àS
@app.put("/tasks/{task_id}", response_model=Task)
async def update_task(
    task_id: str,
    update_data: TaskUpdate,
    db: Session = Depends(get_db)  # ‚ú® AJOUTER db
):
    """Update an existing task."""
    task = db.query(TaskModel).filter(TaskModel.id == task_id).first()

    if not task:
        raise HTTPException(status_code=404, detail=f"Task with ID '{task_id}' not found")

    # Update fields
    update_dict = update_data.model_dump(exclude_unset=True)
    for field, value in update_dict.items():
        setattr(task, field, value)

    task.updated_at = datetime.utcnow()

    db.commit()  # ‚ú® Commit les changements
    db.refresh(task)

    return task
```

**e) Delete Task**

```python
# APR√àS
@app.delete("/tasks/{task_id}", status_code=204)
async def delete_task(task_id: str, db: Session = Depends(get_db)):  # ‚ú® AJOUTER db
    """Delete a task by ID."""
    task = db.query(TaskModel).filter(TaskModel.id == task_id).first()

    if not task:
        raise HTTPException(status_code=404, detail=f"Task with ID '{task_id}' not found")

    db.delete(task)  # ‚ú® Supprimer de la DB
    db.commit()

    return
```

**Changement 6** : Fixer le global exception handler

```python
# APR√àS
@app.exception_handler(Exception)
async def global_exception_handler(request, exc: Exception):
    """Handle unexpected errors gracefully."""
    logger.error(f"Unexpected error: {exc}", exc_info=True)

    return JSONResponse(  # ‚ú® Retourner JSONResponse au lieu de dict
        status_code=500,
        content={
            "detail": "Internal server error",
            "timestamp": datetime.utcnow().isoformat()
        }
    )
```

### √âtape 2.5 : Adapter les Tests

**Fichier √† modifier** : `backend/tests/conftest.py`

**Remplacez tout le contenu** par :

```python
"""
Test Configuration for TaskFlow with database support.
"""

import pytest
import tempfile
import os as os_module
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from src.app import app
from src.database import Base, get_db
from src.models import TaskModel

# Use SQLite file-based database for testing
TEST_DB_FILE = tempfile.mktemp(suffix=".db")
TEST_DATABASE_URL = f"sqlite:///{TEST_DB_FILE}"

test_engine = create_engine(
    TEST_DATABASE_URL,
    connect_args={"check_same_thread": False},
)

TestSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=test_engine)


@pytest.fixture(scope="session", autouse=True)
def setup_test_database():
    """Create database tables once for the entire test session."""
    Base.metadata.create_all(bind=test_engine)
    yield
    Base.metadata.drop_all(bind=test_engine)
    if os_module.path.exists(TEST_DB_FILE):
        os_module.remove(TEST_DB_FILE)


@pytest.fixture(autouse=True)
def clean_database():
    """Clean all data between tests."""
    yield
    session = TestSessionLocal()
    try:
        session.query(TaskModel).delete()
        session.commit()
    finally:
        session.close()


@pytest.fixture
def db_session():
    """Provide a database session for tests."""
    session = TestSessionLocal()
    try:
        yield session
    finally:
        session.close()


@pytest.fixture
def client():
    """Provide a test client with test database."""
    def override_get_db():
        session = TestSessionLocal()
        try:
            yield session
        finally:
            session.close()

    app.dependency_overrides[get_db] = override_get_db

    try:
        with TestClient(app) as test_client:
            yield test_client
    finally:
        app.dependency_overrides.clear()
```

### √âtape 2.6 : Cr√©er les Fichiers de Configuration

**Fichier √† cr√©er** : `backend/.env.example`

```bash
# TaskFlow Backend Environment Variables
ENVIRONMENT=development
DATABASE_URL=sqlite:///./taskflow.db
CORS_ORIGINS=http://localhost:5173,http://localhost:3000
DEBUG=true
LOG_LEVEL=INFO
```

**Fichier √† cr√©er** : `backend/.gitignore`

```text
__pycache__/
*.py[cod]
*.db
*.sqlite
.env
.env.local
htmlcov/
.coverage
.pytest_cache/
.venv/
```

### √âtape 2.7 : Tester Localement

```bash
cd backend

# Installer les d√©pendances
uv sync

# Lancer les tests
uv run pytest -v

# D√©marrer le serveur
uv run uvicorn src.app:app --reload
```

**V√©rifier** :

- ‚úÖ Tous les tests passent (19/19)
- ‚úÖ Le serveur d√©marre sans erreur
- ‚úÖ Le health check retourne `"database": "connected"`
- ‚úÖ Un fichier `taskflow.db` est cr√©√©

**Tester l'API** :

```bash
# Health check
curl http://localhost:8000/health

# Cr√©er une t√¢che
curl -X POST http://localhost:8000/tasks \
  -H "Content-Type: application/json" \
  -d '{"title": "Test DB", "status": "todo", "priority": "high"}'

# Lister les t√¢ches
curl http://localhost:8000/tasks
```

## üìö Partie 3 : Cr√©er la Base de Donn√©es sur Render

### 2.1 Cr√©er l'Instance PostgreSQL

1. Aller sur [dashboard.render.com](https://dashboard.render.com)
2. Cliquer **"New +" ‚Üí "PostgreSQL"**

**Configuration** :

```yaml
Name: taskflow-db
Database: taskflow_prod
User: taskflow_user
Region: Frankfurt (m√™me r√©gion que le backend!)
PostgreSQL Version: 17 (ou 16, 15 - toutes fonctionnent)
Plan: Free (1GB de stockage)
```

**Note** : PostgreSQL 17, 16, et 15 sont toutes compatibles avec notre code. Utilisez la version la plus r√©cente disponible sur Render.

3. Cliquer **"Create Database"**

### 2.2 R√©cup√©rer les Informations de Connexion

Une fois cr√©√©e, Render fournit :

- **Internal Database URL** : Pour se connecter depuis le backend Render
- **External Database URL** : Pour se connecter localement (debugging)
- **PSQL Command** : Pour acc√©der via terminal

**Important** : Utilisez l'**Internal Database URL** en production (pas de frais d'egress).

### 2.3 Configurer le Backend pour Utiliser PostgreSQL

Dans votre service backend Render :

1. Aller dans **Environment**
2. Ajouter/modifier la variable :

```bash
DATABASE_URL=<votre-internal-database-url-de-render>
```

**Note** : Render remplace automatiquement `postgres://` par `postgresql://` pour SQLAlchemy.

## üìö Partie 3 : D√©veloppement Local avec PostgreSQL

### Option A : Utiliser SQLite Localement (Plus Simple)

SQLite est utilis√© automatiquement si `DATABASE_URL` n'est pas d√©fini :

```bash
cd backend
uv sync  # Installer les nouvelles d√©pendances
uv run uvicorn src.app:app --reload
```

Les donn√©es sont stock√©es dans `taskflow.db` (fichier local).

### Option B : Utiliser PostgreSQL Localement (Plus Proche de la Prod)

#### Avec Docker :

```bash
docker run --name taskflow-postgres \
  -e POSTGRES_DB=taskflow_dev \
  -e POSTGRES_USER=taskflow \
  -e POSTGRES_PASSWORD=dev_password \
  -p 5432:5432 \
  -d postgres:15
```

#### Configurer l'Application :

Cr√©er `backend/.env` :

```bash
DATABASE_URL=postgresql://taskflow:dev_password@localhost:5432/taskflow_dev
```

#### D√©marrer l'Application :

```bash
uv run uvicorn src.app:app --reload
```

Les tables sont cr√©√©es automatiquement au d√©marrage !

## üìö Partie 4 : Op√©rations CRUD avec SQLAlchemy

### 4.1 Cr√©er (Create)

```python
@app.post("/tasks", response_model=Task, status_code=201)
async def create_task(task_data: TaskCreate, db: Session = Depends(get_db)):
    # Cr√©er l'instance du mod√®le
    db_task = TaskModel(
        id=str(uuid4()),
        **task_data.model_dump()
    )

    # Ajouter √† la session
    db.add(db_task)

    # Sauvegarder en base de donn√©es
    db.commit()

    # Rafra√Æchir pour obtenir les valeurs g√©n√©r√©es (timestamps)
    db.refresh(db_task)

    return db_task
```

### 4.2 Lire (Read)

```python
@app.get("/tasks", response_model=List[Task])
async def list_tasks(
    status: Optional[TaskStatus] = None,
    db: Session = Depends(get_db)
):
    # Construire la requ√™te
    query = db.query(TaskModel)

    # Filtrer si n√©cessaire
    if status:
        query = query.filter(TaskModel.status == status.value)

    # Ex√©cuter et retourner
    tasks = query.all()
    return tasks
```

### 4.3 Mettre √† Jour (Update)

```python
@app.put("/tasks/{task_id}", response_model=Task)
async def update_task(
    task_id: str,
    update_data: TaskUpdate,
    db: Session = Depends(get_db)
):
    # Trouver la t√¢che
    task = db.query(TaskModel).filter(TaskModel.id == task_id).first()

    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    # Mettre √† jour les champs
    update_dict = update_data.model_dump(exclude_unset=True)
    for field, value in update_dict.items():
        setattr(task, field, value)

    # Sauvegarder
    db.commit()
    db.refresh(task)

    return task
```

### 4.4 Supprimer (Delete)

```python
@app.delete("/tasks/{task_id}", status_code=204)
async def delete_task(task_id: str, db: Session = Depends(get_db)):
    task = db.query(TaskModel).filter(TaskModel.id == task_id).first()

    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    db.delete(task)
    db.commit()

    return
```

## üìö Partie 5 : Tests avec Base de Donn√©es

### 5.1 Configuration des Tests (`conftest.py`)

Les tests utilisent une **base SQLite en m√©moire** :

```python
import pytest
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Base de donn√©es de test en m√©moire
TEST_DATABASE_URL = "sqlite:///:memory:"

test_engine = create_engine(
    TEST_DATABASE_URL,
    connect_args={"check_same_thread": False}
)

TestSessionLocal = sessionmaker(bind=test_engine)

@pytest.fixture(autouse=True)
def setup_database():
    """Cr√©er les tables avant chaque test."""
    Base.metadata.create_all(bind=test_engine)
    yield
    Base.metadata.drop_all(bind=test_engine)
```

### 5.2 Override de la D√©pendance

```python
@pytest.fixture
def client(db_session):
    """Client de test avec base de donn√©es de test."""
    def override_get_db():
        yield db_session

    app.dependency_overrides[get_db] = override_get_db

    with TestClient(app) as test_client:
        yield test_client

    app.dependency_overrides.clear()
```

### 5.3 Lancer les Tests

```bash
cd backend
uv run pytest -v
```

Les tests utilisent SQLite en m√©moire, donc pas besoin de PostgreSQL local !

## üìö Partie 6 : D√©ploiement sur Render

### 6.1 Workflow de D√©ploiement

1. **Commit les changements** :

```bash
git add .
git commit -m "feat: add PostgreSQL database integration"
git push origin main
```

2. **GitHub Actions** ex√©cute les tests automatiquement

3. **Render d√©tecte le push** et red√©ploie le backend

4. **Render injecte automatiquement** `DATABASE_URL`

5. **L'application d√©marre** et cr√©e les tables automatiquement

### 6.2 V√©rifier le D√©ploiement

#### Health Check :

```bash
curl https://taskflow-backend-XXXX.onrender.com/health
```

R√©ponse attendue :

```json
{
  "status": "healthy",
  "timestamp": "2025-10-22T...",
  "environment": "production",
  "version": "2.1.0",
  "storage": "postgresql",
  "database": "connected"
}
```

#### Cr√©er une T√¢che :

```bash
curl -X POST https://taskflow-backend-XXXX.onrender.com/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Test from Production",
    "status": "todo",
    "priority": "high"
  }'
```

#### Lister les T√¢ches :

```bash
curl https://taskflow-backend-XXXX.onrender.com/tasks
```

### 6.3 Acc√©der √† la Base de Donn√©es (Debug)

Via le dashboard Render :

1. Aller dans votre service PostgreSQL
2. Cliquer sur **"Connect"**
3. Copier la commande PSQL

Ou via le PSQL Command fourni :

```bash
PGPASSWORD=<password> psql -h <host> -U <user> <database>
```

Puis ex√©cuter des requ√™tes SQL :

```sql
-- Voir toutes les tables
\dt

-- Compter les t√¢ches
SELECT COUNT(*) FROM tasks;

-- Voir les t√¢ches
SELECT id, title, status FROM tasks LIMIT 10;
```

## üìö Partie 7 : Migrations de Base de Donn√©es (Avanc√©)

Pour des projets plus complexes, utilisez **Alembic** pour les migrations :

### Installation :

```bash
uv add alembic
```

### Initialisation :

```bash
cd backend
alembic init migrations
```

### Cr√©er une Migration :

```bash
alembic revision --autogenerate -m "Initial tables"
```

### Appliquer les Migrations :

```bash
alembic upgrade head
```

**Note** : Pour cet atelier, nous utilisons `Base.metadata.create_all()` pour plus de simplicit√©.

## üéØ Exercices Pratiques

### Exercice 1 : Ajouter un Index

Optimiser les requ√™tes par status :

```python
class TaskModel(Base):
    # ...
    status = Column(Enum(TaskStatus), index=True)  # Ajouter index=True
```

### Exercice 2 : Ajouter une Relation

Cr√©er un mod√®le `User` et lier les t√¢ches :

```python
class UserModel(Base):
    __tablename__ = "users"
    id = Column(String, primary_key=True)
    name = Column(String(100))
    tasks = relationship("TaskModel", back_populates="user")

class TaskModel(Base):
    # ...
    user_id = Column(String, ForeignKey("users.id"))
    user = relationship("UserModel", back_populates="tasks")
```

### Exercice 3 : Requ√™te Complexe

Compter les t√¢ches par statut :

```python
from sqlalchemy import func

@app.get("/tasks/stats")
async def get_stats(db: Session = Depends(get_db)):
    stats = db.query(
        TaskModel.status,
        func.count(TaskModel.id).label("count")
    ).group_by(TaskModel.status).all()

    return [{"status": s, "count": c} for s, c in stats]
```

## üêõ D√©pannage

### Probl√®me : "Relation 'tasks' does not exist"

**Solution** : Les tables ne sont pas cr√©√©es. Red√©marrer l'application pour d√©clencher `init_db()`.

### Probl√®me : "Connection refused"

**Solution** : V√©rifier que `DATABASE_URL` est correctement d√©finie et accessible.

### Probl√®me : Tests √©chouent avec "no such table"

**Solution** : V√©rifier que `setup_database` fixture est bien utilis√©e dans `conftest.py`.

### Probl√®me : "Passwords do not match" sur Render

**Solution** : Copier exactement l'**Internal Database URL** sans modification.

## üìä Checklist de Compl√©tion

- [ ] Base PostgreSQL cr√©√©e sur Render
- [ ] `DATABASE_URL` configur√©e dans l'environnement backend
- [ ] Application d√©marre localement avec la base de donn√©es
- [ ] Tests passent avec la base de test en m√©moire
- [ ] Application d√©ploy√©e sur Render avec PostgreSQL
- [ ] Health check indique `"storage": "postgresql"`
- [ ] Donn√©es persistent apr√®s red√©marrage de l'application

## üìö Ressources

- [SQLAlchemy Documentation](https://docs.sqlalchemy.org/en/20/)
- [FastAPI with Databases](https://fastapi.tiangolo.com/tutorial/sql-databases/)
- [Render PostgreSQL](https://render.com/docs/databases)
- [Alembic Migrations](https://alembic.sqlalchemy.org/)

## üèÜ F√©licitations !

Vous avez maintenant une application **production-ready** avec :

‚úÖ Base de donn√©es persistante
‚úÖ ORM moderne avec SQLAlchemy
‚úÖ Tests isol√©s et reproductibles
‚úÖ D√©ploiement cloud avec PostgreSQL manag√©
‚úÖ Architecture scalable et maintenable

**Prochaines √©tapes** :
- Ajouter l'authentification utilisateur
- Impl√©menter des migrations avec Alembic
- Ajouter des sauvegardes automatiques
- Configurer un monitoring de la base de donn√©es

---

**Version 2.2.0** - Atelier 3 avec Base de Donn√©es PostgreSQL üöÄ
