# ðŸŽ“ Atelier 1 : Tests Unitaires Backend & Frontend

**DurÃ©e :** 3-4 heures
**Objectif :** Apprendre les tests unitaires avec Python (pytest) et TypeScript (Vitest)

---

## ðŸ“‹ Vue d'Ensemble

Dans cet atelier, vous allez :

- âœ… Tester le **backend Python** avec pytest (FastAPI)
- âœ… Tester le **frontend TypeScript** avec Vitest (React)
- âœ… Comprendre le stockage en mÃ©moire (prÃ©paration pour Atelier 3)
- âœ… Configurer **GitHub Actions** pour l'intÃ©gration continue
- âœ… Lancer l'application en local (frontend + backend)

**Important :** L'application est dÃ©jÃ  construite. Vous allez apprendre Ã  la tester et Ã  garantir sa qualitÃ© !

---

## Phase 1 : Installation & Configuration (30 min)

### Ã‰tape 1.1 : Forker le DÃ©pÃ´t

1. Allez sur `https://github.com/umons/edl-starter`
2. Cliquez sur **"Fork"**
3. Clonez votre fork :

   ```bash
   git clone https://github.com/VOTRE_NOM/edl-starter
   cd edl-starter
   ```

### Ã‰tape 1.2 : Installer UV

**macOS/Linux :**

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Windows :**

```powershell
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

VÃ©rifiez :

```bash
uv --version
```

### Ã‰tape 1.3 : Installer les DÃ©pendances

```bash
cd backend
uv venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
uv sync
```

**Qu'est-ce que Ã§a fait ?**

- `uv venv` â†’ CrÃ©e un environnement virtuel isolÃ©
- `source .venv/bin/activate` â†’ Active l'environnement
- `uv sync` â†’ Installe toutes les dÃ©pendances depuis `pyproject.toml`

---

## Phase 2 : Explorer l'Application (15 min)

### Ã‰tape 2.1 : Lancer le Serveur

```bash
uv run uvicorn src.app:app --reload
```

### Ã‰tape 2.2 : Tester dans le Navigateur

Visitez :

- **API :** <http://localhost:8000>
- **Documentation interactive :** <http://localhost:8000/docs>
- **SantÃ© :** <http://localhost:8000/health>

### Ã‰tape 2.3 : Tester avec Swagger UI

1. Allez sur <http://localhost:8000/docs>
2. Cliquez sur **POST /tasks**
3. Cliquez sur **"Try it out"**
4. Entrez :

   ```json
   {
     "title": "Ma premiÃ¨re tÃ¢che",
     "description": "Apprendre FastAPI"
   }
   ```

5. Cliquez sur **"Execute"**
6. Vous devriez voir un code `201 Created`

### Ã‰tape 2.4 : Explorer le Code

Ouvrez `backend/src/app.py` dans votre Ã©diteur :

- **Lignes 27-36 :** Ã‰numÃ©rations (TaskStatus, TaskPriority)
- **Lignes 39-68 :** ModÃ¨les Pydantic
- **Lignes 76-77 :** Stockage en mÃ©moire (dictionnaire simple)
- **Lignes 180-205 :** Endpoint pour crÃ©er une tÃ¢che
- **Lignes 144-160 :** Endpoint pour lister les tÃ¢ches

**Important :** Ce backend utilise un **stockage en mÃ©moire** (un simple dictionnaire Python) pour Atelier 1 & 2. Vous apprendrez Ã  utiliser PostgreSQL dans l'Atelier 3.

---

## Phase 3 : Comprendre les Tests (20 min)

### Ã‰tape 3.1 : Explorer les Fichiers de Test

Ouvrez ces fichiers :

- `backend/tests/conftest.py` â†’ Fixtures de test
- `backend/tests/test_api.py` â†’ Tests

### Ã‰tape 3.2 : Qu'est-ce qu'une Fixture ?

Dans `conftest.py`, regardez :

```python
@pytest.fixture(autouse=True)
def clean_tasks():
    """Nettoie les tÃ¢ches avant et aprÃ¨s chaque test"""
    clear_tasks()
    yield
    clear_tasks()

@pytest.fixture
def client():
    """Fournit un client HTTP de test"""
    with TestClient(app) as test_client:
        yield test_client
```

**Pourquoi c'est utile ?**

- `clean_tasks` : Nettoie automatiquement le stockage en mÃ©moire avant chaque test
- `client` : Vous n'avez pas Ã  crÃ©er un client dans chaque test
- pytest les injecte automatiquement quand vous Ã©crivez `def test_xxx(client):`

### Ã‰tape 3.3 : Lancer les Tests Existants

```bash
uv run pytest -v
```

Vous devriez voir :

```text
tests/test_api.py::test_root_endpoint PASSED
tests/test_api.py::test_health_check PASSED
tests/test_api.py::test_create_task PASSED
tests/test_api.py::test_list_tasks PASSED
tests/test_api.py::test_get_task_by_id PASSED
... (19 tests au total)

========== 19 passed in 0.45s ==========
```

### Ã‰tape 3.4 : Comprendre un Test

Regardez `test_create_task` dans `test_api.py` :

```python
def test_create_task(client):
    # ARRANGE : PrÃ©parer les donnÃ©es
    new_task = {
        "title": "Acheter des courses",
        "description": "Lait, Å“ufs, pain"
    }

    # ACT : Faire la requÃªte
    response = client.post("/tasks", json=new_task)

    # ASSERT : VÃ©rifier
    assert response.status_code == 201
    assert response.json()["title"] == "Acheter des courses"
```

**Pattern Arrange-Act-Assert :**

1. **Arrange** â†’ PrÃ©parer
2. **Act** â†’ Agir
3. **Assert** â†’ VÃ©rifier

---

## Phase 4 : Ã‰crire Vos Tests (45 min)

### ðŸŽ¯ Exercice 1 : Test DELETE (15 min - Ã€ faire ensemble)

**Objectif :** Ã‰crire un test qui supprime une tÃ¢che

**Ã‰tapes :**

1. CrÃ©er une tÃ¢che
2. Obtenir son ID
3. La supprimer avec `client.delete()`
4. VÃ©rifier qu'elle a disparu (404)

**Travaillons ensemble :**

```python
def test_delete_task(client):
    # 1. CrÃ©er une tÃ¢che
    create_response = client.post("/tasks", json={"title": "Ã€ supprimer"})
    task_id = create_response.json()["id"]

    # 2. Supprimer la tÃ¢che
    delete_response = client.delete(f"/tasks/{task_id}")
    assert delete_response.status_code == 204

    # 3. VÃ©rifier qu'elle a disparu
    get_response = client.get(f"/tasks/{task_id}")
    assert get_response.status_code == 404
```

**Points clÃ©s :**

- âš ï¸ N'oubliez pas le `f` dans `f"/tasks/{task_id}"`
- âš ï¸ DELETE retourne 204, pas 200
- âš ï¸ Il faut VÃ‰RIFIER que la tÃ¢che a bien disparu

### âœï¸ Exercice 2 : Test UPDATE (10 min - Ã€ faire seul)

ComplÃ©tez `test_update_task` dans `test_api.py` :

**Objectif :** Mettre Ã  jour le titre d'une tÃ¢che

**Astuce :** C'est similaire au test DELETE, mais avec `client.put()`

### âœï¸ Exercice 3 : Test Validation Titre Vide (5 min)

ComplÃ©tez `test_create_task_empty_title` :

**Objectif :** VÃ©rifier qu'un titre vide est refusÃ©

```python
def test_create_task_empty_title(client):
    response = client.post("/tasks", json={"title": ""})
    assert response.status_code == 422  # Erreur de validation
```

### âœï¸ Exercice 4 : Test Titre Manquant (5 min)

ComplÃ©tez `test_create_task_no_title` :

**Objectif :** VÃ©rifier qu'une tÃ¢che sans titre est refusÃ©e

### âœï¸ Exercice 5 : Test 404 (5 min)

ComplÃ©tez `test_get_nonexistent_task` :

**Objectif :** VÃ©rifier qu'obtenir une tÃ¢che inexistante retourne 404

### ðŸŽ Exercices Bonus (Si vous avez le temps)

- **Bonus 1 :** Tester le filtrage par statut
- **Bonus 2 :** Tester la mise Ã  jour partielle
- **Bonus 3 :** Tester le cycle de vie complet

---

## Phase 5 : Couverture de Code (15 min)

### Ã‰tape 5.1 : Lancer les Tests avec Couverture

```bash
uv run pytest --cov
```

RÃ©sultat :

```text
---------- coverage: platform darwin, python 3.12.7 -----------
Name                Stmts   Miss  Cover
---------------------------------------
src/app.py            156      6    96%
---------------------------------------
TOTAL                 156      6    96%
```

**Note :** La couverture est trÃ¨s Ã©levÃ©e (96%) car le backend est simple avec stockage en mÃ©moire. Dans l'Atelier 3, vous ajouterez une base de donnÃ©es PostgreSQL.

### Ã‰tape 5.2 : GÃ©nÃ©rer un Rapport HTML

```bash
uv run pytest --cov --cov-report=html
```

Ouvrir le rapport :

```bash
open htmlcov/index.html  # macOS
start htmlcov/index.html  # Windows
```

**Questions Ã  se poser :**

- Quelles lignes ne sont pas testÃ©es ?
- Est-ce important de les tester ?
- Le backend utilise un stockage en mÃ©moire - simple et parfait pour l'apprentissage !
- Dans l'Atelier 3, vous migrerez vers PostgreSQL pour la persistance des donnÃ©es

---

## Phase 6 : Tests Frontend (30 min)

### Ã‰tape 6.1 : Comprendre le Frontend

Le frontend est une application **React + TypeScript** simple qui communique avec le backend.

**Structure :**
```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.tsx              # Composant principal
â”‚   â”œâ”€â”€ App.css              # Styles simples
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ api.ts           # Client API
â”‚   â”‚   â””â”€â”€ api.test.ts      # Tests API â† ON TESTE Ã‡A
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ SimpleTaskList.tsx
â”‚       â””â”€â”€ TaskForm.tsx
â””â”€â”€ package.json
```

**Important :** On teste **uniquement l'API** (pas les composants React) pour rester simple.

### Ã‰tape 6.2 : Lancer les Tests Frontend

```bash
cd frontend
npm test
```

Vous devriez voir :

```
âœ“ src/api/api.test.ts (3 tests) 4ms
  âœ“ fetches tasks from the backend
  âœ“ creates a new task
  âœ“ throws error when API fails

Test Files  1 passed (1)
     Tests  3 passed (3)
```

### Ã‰tape 6.3 : Analyser les Tests

Ouvrez `frontend/src/api/api.test.ts` :

```typescript
describe('API Module', () => {
  it('fetches tasks from the backend', async () => {
    // Mock fetch pour simuler la rÃ©ponse
    (globalThis as any).fetch = vi.fn(() =>
      Promise.resolve({
        ok: true,
        json: () => Promise.resolve([
          { id: 1, title: 'Test Task', status: 'todo' }
        ]),
      })
    );

    const tasks = await api.getTasks();
    expect(tasks).toHaveLength(1);
    expect(tasks[0].title).toBe('Test Task');
  });
});
```

**Concepts clÃ©s :**
- **Mocking** : On simule `fetch()` pour ne pas appeler le vrai backend
- **async/await** : Tests asynchrones
- **expect()** : Assertions Vitest (similaire Ã  pytest)

### Ã‰tape 6.4 : Couverture Frontend

```bash
npm run test:coverage
```

RÃ©sultat :

```
File       | % Stmts | % Branch | % Funcs | % Lines |
-----------|---------|----------|---------|---------|
api.ts     |   68.42 |    55.55 |      50 |   68.42 |
```

**Note :** On teste uniquement l'API (pas les composants React) pour Atelier 1. C'est suffisant !

### Ã‰tape 6.5 : Lancer l'Application ComplÃ¨te

**Terminal 1 - Backend :**
```bash
cd backend
uv run uvicorn src.app:app --reload
```

**Terminal 2 - Frontend :**
```bash
cd frontend
npm run dev
```

**Ouvrir :** http://localhost:5173

Vous pouvez crÃ©er/modifier/supprimer des tÃ¢ches ! ðŸŽ‰

**âš ï¸ Important :** Les donnÃ©es sont en mÃ©moire. Si vous redÃ©marrez le backend, tout est perdu (c'est normal pour Atelier 1-2).

---

## Phase 7 : GitHub Actions (40 min)

### Ã‰tape 7.1 : CrÃ©er le Fichier Workflow

```bash
touch .github/workflows/test.yml
```

### Ã‰tape 7.2 : Ã‰crire le Workflow

Ouvrez `.github/workflows/test.yml` et ajoutez :

```yaml
name: Tests Backend

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - name: RÃ©cupÃ©rer le code
      uses: actions/checkout@v4

    - name: Installer Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Installer UV
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.local/bin" >> $GITHUB_PATH

    - name: Installer les dÃ©pendances
      run: |
        cd backend
        uv venv
        uv sync

    - name: Lancer les tests
      run: |
        cd backend
        uv run pytest -v --cov

    - name: VÃ©rifier la couverture
      run: |
        cd backend
        uv run pytest --cov --cov-fail-under=90
```

### Ã‰tape 7.3 : Comprendre le Workflow

**DÃ©clencheurs (`on`) :**

- Se lance quand vous poussez sur `main`
- Se lance sur chaque pull request

**Ã‰tapes (`steps`) :**

1. RÃ©cupÃ©rer le code
2. Installer Python 3.11
3. Installer UV
4. Installer les dÃ©pendances
5. Lancer les tests
6. VÃ©rifier que la couverture est â‰¥ 90%

### Ã‰tape 7.4 : Pousser sur GitHub

```bash
git add .
git commit -m "Ajout des tests et du workflow CI/CD"
git push origin main
```

### Ã‰tape 7.5 : VÃ©rifier sur GitHub

1. Allez sur votre dÃ©pÃ´t GitHub
2. Cliquez sur l'onglet **"Actions"**
3. Vous verrez votre workflow en cours d'exÃ©cution
4. Attendez la coche verte âœ…

**Si Ã§a Ã©choue :**

- Cliquez sur le workflow rouge
- Regardez quelle Ã©tape a Ã©chouÃ©
- Lisez le message d'erreur
- Corrigez et poussez Ã  nouveau

---

## Phase 8 : VÃ©rification Finale (15 min)

### âœ… Liste de ContrÃ´le

VÃ©rifiez que vous avez :

**Backend :**
- [ ] UV installÃ© (`uv --version` fonctionne)
- [ ] Backend qui tourne localement (http://localhost:8000)
- [ ] Tous les tests backend qui passent (19 tests)
- [ ] ComprÃ©hension du stockage en mÃ©moire (dictionnaire Python)
- [ ] Couverture backend > 90% (actuellement 96%)

**Frontend :**
- [ ] Frontend qui tourne localement (http://localhost:5173)
- [ ] Tous les tests frontend qui passent (3 tests API)
- [ ] ComprÃ©hension du mocking avec Vitest
- [ ] Application complÃ¨te fonctionnelle (crÃ©er/modifier/supprimer des tÃ¢ches)

**CI/CD :**
- [ ] Fichier `.github/workflows/test.yml` crÃ©Ã©
- [ ] Tests qui passent sur GitHub âœ…

### ðŸŽ“ Ce que Vous Avez Appris

**UV :**

- âœ… Installation et configuration
- âœ… `uv venv` et `uv sync`
- âœ… Gestion moderne des dÃ©pendances

**pytest :**

- âœ… Structure d'un test (Arrange-Act-Assert)
- âœ… Fixtures (`client`, `reset_storage`)
- âœ… Lancer des tests
- âœ… Couverture de code

**HTTP Testing :**

- âœ… GET, POST, PUT, DELETE
- âœ… Codes de statut (200, 201, 204, 404, 422)
- âœ… Validation des donnÃ©es

**GitHub Actions :**

- âœ… CrÃ©er un workflow
- âœ… Tests automatisÃ©s
- âœ… IntÃ©gration continue (CI)

---

## ðŸ†˜ ProblÃ¨mes Courants

### "Module not found"

â†’ Activez l'environnement virtuel : `source .venv/bin/activate`

### "No module named 'src'"

â†’ Vous devez Ãªtre dans `backend/` : `cd backend`

### Tests qui Ã©chouent

â†’ Lancez un seul test : `uv run pytest tests/test_api.py::test_create_task -v -s`

### Workflow GitHub qui Ã©choue

â†’ VÃ©rifiez que vous avez bien `cd backend` avant chaque commande

---

## ðŸ“š Ressources

- [Documentation FastAPI](https://fastapi.tiangolo.com/)
- [Documentation pytest](https://docs.pytest.org/)
- [Documentation UV](https://docs.astral.sh/uv/)
